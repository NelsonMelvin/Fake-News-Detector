# -*- coding: utf-8 -*-
"""Fake News Dictector

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1e5Tf1uK9KzKZL8QwJjNr3b6Xclr6-eCj
"""

import pandas as pd
df = pd.read_csv('/content/Fake.csv')
df_real = pd.read_csv("/content/True.csv")

df = df.head(3000)
df_real = df_real.head(3000)

# Keep only first 3000 rows
df.head(3000).to_csv("Fake_small.csv", index=False)
df_real.head(3000).to_csv("True_small.csv", index=False)

df['label'] = 0 #Fake
df_real['label'] = 1 #True

data = pd.concat([df, df_real])
data.sample(frac=1).reset_index(drop=True)

import nltk
from nltk.corpus import stopwords
import string

nltk.download('stopwords')
stop_words = set(stopwords.words('english'))

import nltk
from nltk.corpus import stopwords
import string

nltk.download('stopwords')
stop_words = set(stopwords.words('english'))

def clean_text(text):
  text = text.lower()
  text = ''.join([char for char in text if char not in string.punctuation])
  words = text.split()
  words =[word for word in words if word not in stop_words]
  return ' '.join(words)

data['text'] = data['text'].apply(clean_text)

#Convert Text to Vectors (Features)
from sklearn.feature_extraction.text import TfidfVectorizer

vectorizer = TfidfVectorizer()
X = vectorizer.fit_transform(data['text'])
y = data['label']

#Train/Test Split
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

#Train a Classifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report

model = LogisticRegression()
model.fit(X_train, y_train)

y_pred = model.predict(X_test)
print("accuracy:", accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred))

import joblib

# Save the trained model and vectorizer
joblib.dump(model, 'model.pkl')
joblib.dump(vectorizer, 'vectorizer.pkl')

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
import joblib

# Example DataFrame df with the 'text' and 'label' columns
# Clean your text data first, as done previously

# Step 1: Train the Vectorizer
vectorizer = TfidfVectorizer()
X = vectorizer.fit_transform(data['text'])  # Fit the vectorizer on the 'text' column

# Step 2: Train the Model
model = LogisticRegression()
model.fit(X, data['label']) # Fit the model on the vectorized data

# Step 3: Save both the vectorizer and the model
joblib.dump(vectorizer, 'vectorizer.pkl')
joblib.dump(model, 'model.pkl')

print(data['label'].value_counts())

from google.colab import files
files.download("model.pkl")
files.download("vectorizer.pkl")

joblib.dump(model, "model.pkl")
joblib.dump(vectorizer, "vectorizer.pkl")

from google.colab import files
files.download("model.pkl")
files.download("vectorizer.pkl")

# Make it Interactive
# Install the streamlit library
# app.py
import streamlit as st

text_input = st.text_area("Paste a news article:")
if st.button("Check if it's Fake or Real"):
  cleaned = clean_text(text_input)
  vectorized = vectorizer.transform([cleaned])
  prediction = model.predict(vectorized)[0]
  result = "Real" if prediction == 1 else "Fake"
  st.write("This news is:", result)

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# import streamlit as st
# st.title("Fake News Detection")

# Write a simple Streamlit app to a file
with open("app.py", "w") as f:
    f.write("""
import streamlit as st

""")

!streamlit run app.py &>/dev/null &

! streamlit run app.py
